{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDNduhsYSXk9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import string\n",
        "import nltk\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.util import ngrams,bigrams,trigrams\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7yJ16GWO-mc",
        "outputId": "c0cc7600-30a4-41d1-f757-4cd4f41db951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Başladı\n"
          ]
        }
      ],
      "source": [
        "print(\"Başladı\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# i=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC3fEeqIPOEl"
      },
      "outputs": [],
      "source": [
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "def clean_sent(sent):\n",
        "    return \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
        "     if w.lower() in words or not (w.isalpha() and w.isnumeric()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPL0U7ywPMKR"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/WS/Girdi/X.txt', 'r', encoding='utf-8')as f:\n",
        "    json_object = (f.read()).lower()\n",
        "\n",
        "    cleaned_text = json_object.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokenized_words = word_tokenize(cleaned_text,\"english\")\n",
        "\n",
        "    final_words = []\n",
        "\n",
        "    for word in tokenized_words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            final_words.append(word)\n",
        "\n",
        "    lemma_words = []\n",
        "\n",
        "    for word in final_words:\n",
        "        word = WordNetLemmatizer().lemmatize(word)\n",
        "        lemma_words.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC25qh1P1TS3"
      },
      "outputs": [],
      "source": [
        "nonnumword = []\n",
        "\n",
        "for word in lemma_words:\n",
        "  if word.lower() is not word.isnumeric():\n",
        "    nonnumword.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopWords = set(stopwords.words('english'))\n",
        "wordnetLemmatizer = WordNetLemmatizer()\n",
        "punctuationList=[]\n",
        "punctuationList[:0] = string.punctuation\n",
        "punctuationList.append(\"''\")"
      ],
      "metadata": {
        "id": "I4V5er8Q3EW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleanedLemmatizedTokens = []\n",
        "cleanedLemmatizedTokens.append([wordnetLemmatizer.lemmatize(token) for token in nonnumword if (not token.isnumeric()\n",
        "                                                                                      and token not in stopWords and\n",
        "                                                                                    token not in punctuationList and\n",
        "                                                                                token != 'nan' and len(token) > 2)])"
      ],
      "metadata": {
        "id": "AJ_6bEVV22N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utvIxgUKGsFi"
      },
      "outputs": [],
      "source": [
        "# nonnumword.remove('    \"\": 1452652,\\n')\n",
        "# nonnumword.remove('{\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWpfcSkRUXnH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(nonnumword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq6RlDRK_Jcd",
        "outputId": "3d43dcd5-9aa4-457d-9ae1-17e9bc24f597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(cleanedLemmatizedTokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3alDmJf-76O",
        "outputId": "ca95c4de-38fe-496c-b3e7-ca8e5581632f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleanedLemmatizedTokens[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIpRfrp7_tW9",
        "outputId": "c40e2f42-8e9e-434a-cba5-10c0729b80da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5670096"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHhiLs9ZUSbW"
      },
      "outputs": [],
      "source": [
        "t = pd.DataFrame(cleanedLemmatizedTokens[0], columns=['word'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeeiILZXYlkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f0a037-0c84-40d0-ed83-c1eede1e09de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['word'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "t.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jg8w8E2T-1C"
      },
      "outputs": [],
      "source": [
        "t['word'] = t['word'].apply(clean_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EPbp-j5PhEr"
      },
      "outputs": [],
      "source": [
        "# if i % 100 == 0:\n",
        "#         seconds = time.time()\n",
        "#         print(i+1, time.ctime(seconds))\n",
        "    \n",
        "# i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4BlxAS8ZT4o"
      },
      "outputs": [],
      "source": [
        "p = t['word']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgvVA5k7PQ7p"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/WS/Çıktılar/DataUni.json', 'w', encoding='utf-8') as uni:\n",
        "    frq = FreqDist(p)\n",
        "    json.dump(frq, uni, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEUMe_LVPjKK"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/WS/Çıktılar/DataBigrams.json', 'w', encoding='utf-8') as bi:\n",
        "    frqbi = FreqDist(list(nltk.bigrams(p)))\n",
        "    json.dump(list(frqbi.items()), bi, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfH6QXy4Psyq"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/WS/Çıktılar/DataTrigrams.json', 'w', encoding='utf-8') as tri:\n",
        "    frqtri = FreqDist(list(nltk.trigrams(p)))\n",
        "    json.dump(list(frqtri.items()), tri, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZaRye2SPt38"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/WS/Çıktılar/DataN4grams.json', 'w', encoding='utf-8') as n4:\n",
        "    frq4n = FreqDist(list(nltk.ngrams(p,4)))\n",
        "    json.dump(list(frq4n.items()), n4, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUWP_9biCn6X"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/WS/Çıktılar/DataN5grams.json', 'w', encoding='utf-8') as n5:\n",
        "    frq5n = FreqDist(list(nltk.ngrams(p,5)))\n",
        "    json.dump(list(frq5n.items()), n5, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQQnNBfQPvWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78df7b08-f233-490b-d258-98d7a33593c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1592.860459804535 seconds ---\n",
            "Bitti\n"
          ]
        }
      ],
      "source": [
        "bi.close()\n",
        "tri.close()\n",
        "n4.close()\n",
        "n5.close()\n",
        "uni.close()\n",
        "f.close()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(\"Bitti\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}